"""Agent-based system for GitHub to Dockerfile generation with reflection capabilities."""

import asyncio
import json
import os
import logging
from typing import Dict, Any, Optional, List
from fastapi import FastAPI, Request, Form, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from pathlib import Path

from api_analytics.fastapi import Analytics
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict

from tools import clone_repo_tool, gitingest_tool, create_container_tool, build_docker_image

# Load environment variables
load_dotenv()

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(title="GitHub to Dockerfile Generator - Agent Version")

# Add API Analytics middleware
app.add_middleware(Analytics, api_key=os.getenv("FASTAPI_ANALYTICS_KEY"))

# Setup templates
templates = Jinja2Templates(directory="templates")

# Mount static files
static_dir = Path("static")
static_dir.mkdir(exist_ok=True)
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# Store for session data
sessions = {}


class WorkflowState(TypedDict):
    """å®šä¹‰å·¥ä½œæµçŠ¶æ€"""
    repo_url: str
    additional_instructions: str
    model: Optional[str]
    clone_result: Dict[str, Any]
    analysis_result: Dict[str, Any]
    dockerfile_result: Dict[str, Any]
    build_result: Dict[str, Any]
    reflection_result: Dict[str, Any]
    iteration: int
    max_iterations: int
    final_result: Dict[str, Any]
    websocket: Optional[Any]
    messages: List[Any]


def parse_available_models():
    """
    Parse the AVAILABLE_MODELS environment variable.
    Format: model_name|stream_support,model_name|stream_support,...
    Example: gpt-4o-mini|true,gpt-4o|true,o1-mini|false,o1|false
    """
    available_models_str = os.getenv("AVAILABLE_MODELS", "")
    if not available_models_str:
        return []
    
    models = []
    for model_entry in available_models_str.split(","):
        model_entry = model_entry.strip()
        if "|" in model_entry:
            model_name, stream_support = model_entry.split("|")
            models.append({
                "name": model_name.strip(),
                "stream": stream_support.strip().lower() == "true"
            })
        else:
            # For backward compatibility, if no | is present, assume stream is supported
            models.append({
                "name": model_entry,
                "stream": True
            })
    return models


def get_model_stream_support(model_name):
    """
    Check if a specific model supports streaming based on AVAILABLE_MODELS environment variable.
    """
    models = parse_available_models()
    for model in models:
        if model["name"] == model_name:
            return model["stream"]
    # Default to True if model not found in the list
    return True


# å®šä¹‰å·¥å…·å‡½æ•°
async def clone_repository(state: WorkflowState) -> WorkflowState:
    """å…‹éš†ä»“åº“å·¥å…·"""
    websocket = state.get("websocket")
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "status",
            "content": "ğŸ”„ Cloning repository..."
        }))
        await websocket.send_text(json.dumps({
            "type": "phase_start",
            "content": "[å…‹éš†é˜¶æ®µå¼€å§‹]",
            "phase_type": "normal"
        }))
    
    logger.info("å…‹éš†Agentå¼€å§‹å·¥ä½œ")
    
    clone_result = await clone_repo_tool(
        github_url=state["repo_url"],
        websocket=websocket
    )
    
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "phase_end",
            "content": "[å…‹éš†é˜¶æ®µç»“æŸ]",
            "phase_type": "normal"
        }))
    
    state["clone_result"] = clone_result
    return state


async def analyze_repository(state: WorkflowState) -> WorkflowState:
    """åˆ†æä»£ç ç»“æ„å·¥å…·"""
    websocket = state.get("websocket")
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "status",
            "content": "ğŸ“Š Analyzing repository structure..."
        }))
        await websocket.send_text(json.dumps({
            "type": "phase_start",
            "content": "[åˆ†æé˜¶æ®µå¼€å§‹]",
            "phase_type": "normal"
        }))
    
    logger.info("åˆ†æAgentå¼€å§‹å·¥ä½œ")
    
    if not state["clone_result"]["success"]:
        state["analysis_result"] = {
            "success": False,
            "error": "Repository cloning failed, cannot analyze"
        }
        if websocket:
            await websocket.send_text(json.dumps({
                "type": "phase_end",
                "content": "[åˆ†æé˜¶æ®µç»“æŸ]",
                "phase_type": "normal"
            }))
        return state
    
    analysis_result = await gitingest_tool(
        local_repo_path=state["clone_result"]["local_path"],
        websocket=websocket
    )
    
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "phase_end",
            "content": "[åˆ†æé˜¶æ®µç»“æŸ]",
            "phase_type": "normal"
        }))
    
    state["analysis_result"] = analysis_result
    return state


async def generate_dockerfile(state: WorkflowState) -> WorkflowState:
    """ç”ŸæˆDockerfileå·¥å…·"""
    websocket = state.get("websocket")
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "status",
            "content": "ğŸ³ Generating Dockerfile with AI..."
        }))
        await websocket.send_text(json.dumps({
            "type": "phase_start",
            "content": "[ç”Ÿæˆé˜¶æ®µå¼€å§‹]",
            "phase_type": "normal"
        }))
    
    logger.info("Dockerfileç”ŸæˆAgentå¼€å§‹å·¥ä½œ")
    
    if not state["analysis_result"]["success"]:
        state["dockerfile_result"] = {
            "success": False,
            "error": "Repository analysis failed, cannot generate Dockerfile"
        }
        if websocket:
            await websocket.send_text(json.dumps({
                "type": "phase_end",
                "content": "[ç”Ÿæˆé˜¶æ®µç»“æŸ]",
                "phase_type": "normal"
            }))
        return state
    
    # Determine if the selected model supports streaming
    stream_support = get_model_stream_support(state["model"]) if state["model"] else True
    
    dockerfile_result = await create_container_tool(
        gitingest_summary=state["analysis_result"]["summary"],
        gitingest_tree=state["analysis_result"]["tree"],
        gitingest_content=state["analysis_result"]["content"],
        project_name=state["clone_result"]["repo_name"],
        additional_instructions=state["additional_instructions"],
        model=state["model"],
        websocket=websocket,
        stream=stream_support
    )
    
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "phase_end",
            "content": "[ç”Ÿæˆé˜¶æ®µç»“æŸ]",
            "phase_type": "normal"
        }))
    
    state["dockerfile_result"] = dockerfile_result
    return state


async def build_image(state: WorkflowState) -> WorkflowState:
    """æ„å»ºDockeré•œåƒå·¥å…·"""
    websocket = state.get("websocket")
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "status",
            "content": "ğŸ”¨ Building Docker image..."
        }))
        await websocket.send_text(json.dumps({
            "type": "phase_start",
            "content": "[æ„å»ºé˜¶æ®µå¼€å§‹]",
            "phase_type": "normal"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": "ğŸš€ å¼€å§‹æ„å»º Docker é•œåƒ...\n"
        }))
    
    logger.info("æ„å»ºAgentå¼€å§‹å·¥ä½œ")
    
    if not state["dockerfile_result"]["success"]:
        state["build_result"] = {
            "success": False,
            "error": "Dockerfile generation failed, cannot build image"
        }
        if websocket:
            await websocket.send_text(json.dumps({
                "type": "build_log",
                "content": "âŒ Dockerfileç”Ÿæˆå¤±è´¥ï¼Œæ— æ³•æ„å»ºé•œåƒ\n"
            }))
            await websocket.send_text(json.dumps({
                "type": "phase_end",
                "content": "[æ„å»ºé˜¶æ®µç»“æŸ]",
                "phase_type": "normal"
            }))
        return state
    
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"ğŸ“¦ é¡¹ç›®åç§°: {state['clone_result']['repo_name']}\n"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"ğŸ“ æœ¬åœ°è·¯å¾„: {state['clone_result']['local_path']}\n"
        }))
    
    build_result = await build_docker_image(
        dockerfile_content=state["dockerfile_result"]["dockerfile"],
        project_name=state["clone_result"]["repo_name"],
        local_path=state["clone_result"]["local_path"],
        websocket=websocket
    )
    
    # Send build result information
    if websocket:
        if build_result["success"]:
            await websocket.send_text(json.dumps({
                "type": "build_log",
                "content": f"âœ… Docker é•œåƒæ„å»ºå®Œæˆ: {build_result['image_tag']}\n"
            }))
        else:
            await websocket.send_text(json.dumps({
                "type": "build_log",
                "content": f"âŒ Docker é•œåƒæ„å»ºå¤±è´¥: {build_result.get('error', 'Unknown error')}\n"
            }))
            # å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®æ›´æ–°æ­¥éª¤çŠ¶æ€
            await websocket.send_text(json.dumps({
                "type": "error",
                "content": f"Docker é•œåƒæ„å»ºå¤±è´¥: {build_result.get('error', 'Unknown error')}"
            }))
        await websocket.send_text(json.dumps({
            "type": "phase_end",
            "content": "[æ„å»ºé˜¶æ®µç»“æŸ]",
            "phase_type": "normal"
        }))
    
    state["build_result"] = build_result
    return state


async def reflect_on_failure(state: WorkflowState) -> WorkflowState:
    """åæ€æ„å»ºå¤±è´¥åŸå› å·¥å…·"""
    websocket = state.get("websocket")
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "status",
            "content": "ğŸ¤” Reflecting on build failure..."
        }))
        await websocket.send_text(json.dumps({
            "type": "phase_start",
            "content": "[åæ€é˜¶æ®µå¼€å§‹]",
            "phase_type": "smart"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": "ğŸ” æ­£åœ¨åˆ†ææ„å»ºå¤±è´¥åŸå› ...\n"
        }))
    
    logger.info("åæ€Agentå¼€å§‹å·¥ä½œ")
    
    if state["build_result"]["success"]:
        # å¦‚æœæ„å»ºæˆåŠŸï¼Œä¸éœ€è¦åæ€
        state["reflection_result"] = {
            "needed": False,
            "improvements": []
        }
        if websocket:
            await websocket.send_text(json.dumps({
                "type": "build_log",
                "content": "âœ… æ„å»ºæˆåŠŸï¼Œæ— éœ€åæ€\n"
            }))
            await websocket.send_text(json.dumps({
                "type": "phase_end",
                "content": "[åæ€é˜¶æ®µç»“æŸ]",
                "phase_type": "smart"
            }))
        return state
    
    # æ„å»ºå¤±è´¥ï¼Œéœ€è¦åæ€
    logger.info("æ£€æµ‹åˆ°æ„å»ºå¤±è´¥ï¼Œå¼€å§‹åˆ†æåŸå› ")
    
    # è·å–å¤±è´¥æ—¥å¿—
    build_log = state["build_result"].get("build_log", "")
    error_message = state["build_result"].get("error", "")
    
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"âŒ é”™è¯¯ä¿¡æ¯: {error_message}\n"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"ğŸ“ æ„å»ºæ—¥å¿—æ‘˜è¦:\n{build_log[-1000:] if build_log else 'æ— æ—¥å¿—'}\n"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": "ğŸ’¡ æ­£åœ¨ç”Ÿæˆæ”¹è¿›å»ºè®®...\n"
        }))
    
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è°ƒç”¨LLMåˆ†æé”™è¯¯åŸå› å¹¶æå‡ºæ”¹è¿›å»ºè®®
    # ç®€åŒ–ç‰ˆæœ¬ï¼Œæˆ‘ä»¬åªè®°å½•é”™è¯¯ä¿¡æ¯
    state["reflection_result"] = {
        "needed": True,
        "build_log": build_log,
        "error_message": error_message,
        "improvements": ["éœ€è¦é‡æ–°ç”ŸæˆDockerfileä»¥è§£å†³æ„å»ºé—®é¢˜"]
    }
    
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"ğŸ¤” åæ€æ„å»ºå¤±è´¥åŸå› : {error_message}\n"
        }))
        await websocket.send_text(json.dumps({
            "type": "phase_end",
            "content": "[åæ€é˜¶æ®µç»“æŸ]",
            "phase_type": "smart"
        }))
    
    return state


async def improve_dockerfile(state: WorkflowState) -> WorkflowState:
    """æ”¹è¿›Dockerfileå·¥å…·"""
    websocket = state.get("websocket")
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "status",
            "content": "ğŸ”„ Improving Dockerfile based on reflection..."
        }))
        await websocket.send_text(json.dumps({
            "type": "phase_start",
            "content": "[æ”¹è¿›é˜¶æ®µå¼€å§‹]",
            "phase_type": "smart"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"ğŸ”§ ç¬¬ {state['iteration'] + 1} æ¬¡å°è¯•æ”¹è¿›Dockerfile...\n"
        }))
    
    logger.info("æ”¹è¿›Agentå¼€å§‹å·¥ä½œ")
    
    if not state["reflection_result"]["needed"]:
        if websocket:
            await websocket.send_text(json.dumps({
                "type": "build_log",
                "content": "âœ… æ— éœ€æ”¹è¿›\n"
            }))
            await websocket.send_text(json.dumps({
                "type": "phase_end",
                "content": "[æ”¹è¿›é˜¶æ®µç»“æŸ]",
                "phase_type": "smart"
            }))
        return state
    
    # åŸºäºåæ€ç»“æœç”Ÿæˆæ”¹è¿›çš„Dockerfile
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨LLMç”Ÿæˆæ–°çš„Dockerfile
    logger.info("åŸºäºåæ€ç»“æœé‡æ–°ç”ŸæˆDockerfile")
    
    if websocket:
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": "ğŸ“ åŸºäºä»¥ä¸‹é”™è¯¯ä¿¡æ¯é‡æ–°ç”ŸæˆDockerfile:\n"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"   é”™è¯¯: {state['reflection_result']['error_message']}\n"
        }))

    # Determine if the selected model supports streaming
    stream_support = get_model_stream_support(state["model"]) if state["model"] else True
    
    dockerfile_result = await create_container_tool(
        gitingest_summary=state["analysis_result"]["summary"],
        gitingest_tree=state["analysis_result"]["tree"],
        gitingest_content=state["analysis_result"]["content"],
        project_name=state["clone_result"]["repo_name"],
        additional_instructions=f"{state['additional_instructions']}\næ„å»ºé”™è¯¯ä¿¡æ¯: {state['reflection_result']['error_message']}",
        model=state["model"],
        websocket=websocket,
        stream=stream_support
    )
    
    state["dockerfile_result"] = dockerfile_result
    state["iteration"] += 1
    
    if websocket:
        if dockerfile_result["success"]:
            await websocket.send_text(json.dumps({
                "type": "build_log",
                "content": "âœ… Dockerfileæ”¹è¿›æˆåŠŸ\n"
            }))
        else:
            await websocket.send_text(json.dumps({
                "type": "build_log",
                "content": f"âŒ Dockerfileæ”¹è¿›å¤±è´¥: {dockerfile_result.get('error', 'Unknown error')}\n"
            }))
            # æ·»åŠ æ˜ç¡®çš„é”™è¯¯æ¶ˆæ¯ç±»å‹ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®å¤„ç†
            await websocket.send_text(json.dumps({
                "type": "error",
                "content": f"Dockerfileæ”¹è¿›å¤±è´¥: {dockerfile_result.get('error', 'Unknown error')}"
            }))
        await websocket.send_text(json.dumps({
            "type": "phase_end",
            "content": "[æ”¹è¿›é˜¶æ®µç»“æŸ]",
            "phase_type": "smart"
        }))
        await websocket.send_text(json.dumps({
            "type": "build_log",
            "content": f"ğŸ”„ é‡æ–°ç”ŸæˆDockerfile (ç¬¬ {state['iteration']} æ¬¡å°è¯•)\n"
        }))
    
    return state


def should_continue(state: WorkflowState) -> str:
    """å†³å®šæ˜¯å¦ç»§ç»­æ„å»ºæˆ–ç»“æŸ"""
    websocket = state.get("websocket")
    
    # å¦‚æœæ„å»ºæˆåŠŸï¼Œç»“æŸ
    if state["build_result"].get("success"):
        if websocket:
            try:
                # ä½¿ç”¨ get_event_loop().create_task æ›¿ä»£ create_task æ¥é¿å… RuntimeWarning
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "status",
                    "content": "âœ… æ„å»ºæˆåŠŸï¼Œå·¥ä½œæµç»“æŸ"
                })))
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                pass
        return "success"
    
    # å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç»“æŸ
    if state["iteration"] >= state["max_iterations"]:
        if websocket:
            try:
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "status",
                    "content": f"â¹ï¸ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({state['max_iterations']})ï¼Œå·¥ä½œæµç»“æŸ"
                })))
                try:
                    asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                        "type": "build_log",
                        "content": f"â¹ï¸ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({state['max_iterations']})ï¼Œå·¥ä½œæµç»“æŸ\n"
                    })))
                except RuntimeError:
                    # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                    pass
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                pass
        return "max_iterations_reached"
    
    # å¦‚æœéœ€è¦åæ€ï¼Œè¿›å…¥åæ€æµç¨‹
    if not state["build_result"].get("success"):
        if websocket:
            try:
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "status",
                    "content": "ğŸ”„ æ„å»ºå¤±è´¥ï¼Œè¿›å…¥åæ€é˜¶æ®µ"
                })))
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                pass
        return "reflect"
    
    if websocket:
        try:
            asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                "type": "status",
                "content": "ğŸ”š å·¥ä½œæµç»“æŸ"
            })))
        except RuntimeError:
            # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
            pass
    return "end"


def should_retry(state: WorkflowState) -> str:
    """å†³å®šæ˜¯å¦é‡è¯•æ„å»º"""
    websocket = state.get("websocket")
    
    # å¦‚æœæ”¹è¿›åå¯ä»¥é‡è¯•
    if state["dockerfile_result"]["success"] and state["iteration"] < state["max_iterations"]:
        if websocket:
            try:
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "status",
                    "content": "ğŸ”„ Dockerfileå·²æ”¹è¿›ï¼Œé‡æ–°å°è¯•æ„å»º"
                })))
                try:
                    asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                        "type": "build_log",
                        "content": f"ğŸ”„ Dockerfileå·²æ”¹è¿›ï¼Œé‡æ–°å°è¯•æ„å»º (ç¬¬ {state['iteration'] + 1} æ¬¡å°è¯•)\n"
                    })))
                except RuntimeError:
                    # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                    pass
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                pass
        return "retry"
    
    # å¦åˆ™ç»“æŸ
    if websocket:
        if not state["dockerfile_result"]["success"]:
            try:
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "status",
                    "content": "âŒ Dockerfileæ”¹è¿›å¤±è´¥ï¼Œå·¥ä½œæµç»“æŸ"
                })))
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "build_log",
                    "content": "âŒ Dockerfileæ”¹è¿›å¤±è´¥ï¼Œå·¥ä½œæµç»“æŸ\n"
                })))
                # æ·»åŠ æ˜ç¡®çš„é”™è¯¯æ¶ˆæ¯ç±»å‹ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®å¤„ç†
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "error",
                    "content": "Dockerfileæ”¹è¿›å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–æ”¹è¿›è¿‡ç¨‹å‡ºé”™"
                })))
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                pass
        elif state["iteration"] >= state["max_iterations"]:
            try:
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "status",
                    "content": "â¹ï¸ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå·¥ä½œæµç»“æŸ"
                })))
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "build_log",
                    "content": "â¹ï¸ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå·¥ä½œæµç»“æŸ\n"
                })))
                # æ·»åŠ æ˜ç¡®çš„é”™è¯¯æ¶ˆæ¯ç±»å‹ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®å¤„ç†
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "error",
                    "content": "å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ŒDockeré•œåƒæ„å»ºå¤±è´¥"
                })))
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                pass
        else:
            try:
                asyncio.get_event_loop().create_task(websocket.send_text(json.dumps({
                    "type": "status",
                    "content": "ğŸ”š å·¥ä½œæµç»“æŸ"
                })))
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¶ˆæ¯å‘é€
                pass
    return "end"


def create_workflow() -> StateGraph:
    """åˆ›å»ºå·¥ä½œæµå›¾"""
    # åˆ›å»ºå·¥ä½œæµ
    workflow = StateGraph(WorkflowState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("clone", clone_repository)
    workflow.add_node("analyze", analyze_repository)
    workflow.add_node("generate", generate_dockerfile)
    workflow.add_node("build", build_image)
    workflow.add_node("reflect", reflect_on_failure)
    workflow.add_node("improve", improve_dockerfile)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("clone")
    
    # è®¾ç½®æ­£å¸¸æµç¨‹
    workflow.add_edge("clone", "analyze")
    workflow.add_edge("analyze", "generate")
    workflow.add_edge("generate", "build")
    
    # è®¾ç½®æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "build",
        should_continue,
        {
            "success": END,
            "max_iterations_reached": END,
            "reflect": "reflect"
        }
    )
    
    # è®¾ç½®åæ€æµç¨‹
    workflow.add_edge("reflect", "improve")
    workflow.add_conditional_edges(
        "improve",
        should_retry,
        {
            "retry": "build",
            "end": END
        }
    )
    
    return workflow


@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """Home page with the input form."""
    # Get available models from environment variable
    available_models = parse_available_models()
    
    # Get current model - first from available models, or fallback to environment or default
    if available_models:
        current_model = available_models[0]["name"]  # Default to first available model
    else:
        current_model = os.getenv("MODEL", "gpt-4o-mini")
    
    return templates.TemplateResponse("index.jinja", {
        "request": request,
        "repo_url": "",
        "loading": False,
        "streaming": False,
        "result": None,
        "error": None,
        "available_models": [model["name"] for model in available_models],
        "current_model": current_model
    })


@app.get("/{path:path}", response_class=HTMLResponse)
async def dynamic_github_route(request: Request, path: str):
    """Handle GitHub-style URLs by replacing gitcontainer.com with github.com."""
    # Skip certain paths that shouldn't be treated as GitHub routes
    skip_paths = {"health", "favicon.ico", "favicon-16x16.png", "favicon-32x32.png", "apple-touch-icon.png", "static", "ws"}
    
    # Split path into segments
    segments = [segment for segment in path.split('/') if segment]
    
    # If it's a skip path, let it fall through
    if segments and segments[0] in skip_paths:
        from fastapi import HTTPException
        raise HTTPException(status_code=404, detail="Not found")
    
    # Check if we have at least 2 segments (username/repo)
    if len(segments) < 2:
        # Get available models from environment variable
        available_models = parse_available_models()
        
        # Get current model - first from available models, or fallback to environment or default
        if available_models:
            current_model = available_models[0]["name"]  # Default to first available model
        else:
            current_model = os.getenv("MODEL", "gpt-4o-mini")
        
        return templates.TemplateResponse("index.jinja", {
            "request": request,
            "repo_url": "",
            "loading": False,
            "streaming": False,
            "result": None,
            "error": f"Invalid GitHub URL format. Expected format: gitcontainer.com/username/repository",
            "pre_filled": False,
            "available_models": [model["name"] for model in available_models],
            "current_model": current_model
        })
    
    # Use only the first two segments (username/repo)
    username, repo = segments[0], segments[1]
    github_url = f"https://github.com/{username}/{repo}"
    
    # Get available models from environment variable
    available_models = parse_available_models()
    
    # Get current model - first from available models, or fallback to environment or default
    if available_models:
        current_model = available_models[0]["name"]  # Default to first available model
    else:
        current_model = os.getenv("MODEL", "gpt-4o-mini")
    
    return templates.TemplateResponse("index.jinja", {
        "request": request,
        "repo_url": github_url,
        "loading": False,
        "streaming": False,
        "result": None,
        "error": None,
        "pre_filled": True,
        "available_models": [model["name"] for model in available_models],
        "current_model": current_model
    })


@app.post("/", response_class=HTMLResponse)
async def generate_dockerfile_endpoint(
    request: Request, 
    repo_url: str = Form(...),
    additional_instructions_hidden: str = Form(""),
    model: str = Form(None)
):
    """Redirect to streaming page for Dockerfile generation."""
    # Store the repo URL, additional instructions, and model in a session
    session_id = str(hash(repo_url + str(asyncio.get_event_loop().time())))
    sessions[session_id] = {
        "repo_url": repo_url,
        "additional_instructions": additional_instructions_hidden.strip() if additional_instructions_hidden else "",
        "model": model,
        "status": "pending"
    }
    
    # Redirect to streaming page
    # Get available models from environment variable
    available_models = parse_available_models()
    
    # Get current model from form, or first available model, or environment variable
    if model:
        current_model = model
    elif available_models:
        current_model = available_models[0]["name"]  # Default to first available model
    else:
        current_model = os.getenv("MODEL", "gpt-4o-mini")
    
    return templates.TemplateResponse("index.jinja", {
        "request": request,
        "repo_url": repo_url,
        "loading": False,
        "streaming": True,
        "session_id": session_id,
        "result": None,
        "error": None,
        "available_models": [model["name"] for model in available_models],
        "current_model": current_model
    })


@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocket endpoint for streaming Dockerfile generation with multi-agent reflection."""
    await websocket.accept()
    print(f"New WebSocket connection: {session_id}")
    
    try:
        if session_id not in sessions:
            await websocket.send_text(json.dumps({
                "type": "error",
                "content": "Invalid session ID"
            }))
            return
        
        repo_url = sessions[session_id]["repo_url"]
        additional_instructions = sessions[session_id].get("additional_instructions", "")
        model = sessions[session_id].get("model", None)
        
        # ç¼–è¯‘å·¥ä½œæµ
        workflow = create_workflow()
        app_workflow = workflow.compile()
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = WorkflowState(
            repo_url=repo_url,
            additional_instructions=additional_instructions,
            model=model,
            clone_result={},
            analysis_result={},
            dockerfile_result={},
            build_result={},
            reflection_result={},
            iteration=0,
            max_iterations=1,
            final_result={},
            websocket=websocket,
            messages=[]
        )
        
        # è¿è¡Œå·¥ä½œæµ
        final_state = await app_workflow.ainvoke(initial_state)
        
        # æ„é€ æœ€ç»ˆç»“æœ
        if final_state["build_result"].get("success"):
            final_result = {
                "project_name": final_state["dockerfile_result"].get("project_name", ""),
                "technology_stack": final_state["dockerfile_result"].get("technology_stack", ""),
                "dockerfile": final_state["dockerfile_result"].get("dockerfile", ""),
                "base_image_reasoning": final_state["dockerfile_result"].get("base_image_reasoning", ""),
                "additional_notes": final_state["dockerfile_result"].get("additional_notes", ""),
                "image_build": final_state["build_result"],
                "repo_info": {
                    "name": final_state["clone_result"].get("repo_name", ""),
                    "size_mb": final_state["clone_result"].get("repo_size_mb", 0),
                    "file_count": final_state["clone_result"].get("file_count", 0)
                }
            }
            
            await websocket.send_text(json.dumps({
                "type": "complete",
                "content": "Generation complete!",
                "result": final_result
            }))
            
            # Store result in session for potential refresh
            sessions[session_id]["result"] = final_result
            sessions[session_id]["status"] = "complete"
        else:
            # æ„å»ºå¤±è´¥ï¼Œå‘é€é”™è¯¯ä¿¡æ¯
            error_msg = final_state["build_result"].get("error", "Unknown error occurred during build")
            await websocket.send_text(json.dumps({
                "type": "error",
                "content": f"æ„å»ºå¤±è´¥: {error_msg}"
            }))
            
    except WebSocketDisconnect:
        print(f"WebSocket disconnected for session {session_id}")
    except Exception as e:
        error_msg = f"Unexpected error: {str(e)}"
        print(error_msg)
        # Check if websocket is still open before trying to send error message
        try:
            if websocket.client_state.name == 'CONNECTED':
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "content": error_msg
                }))
        except Exception as send_error:
            print(f"Could not send error message, WebSocket likely closed: {send_error}")
    finally:
        # Clean up session data
        try:
            if session_id in sessions:
                sessions[session_id]["status"] = "disconnected"
        except:
            pass


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy"}


if __name__ == "__main__":
    import uvicorn
    # Load environment variables
    load_dotenv()
    PORT = int(os.getenv("PORT", 8000))  # Different port from main app
    uvicorn.run(app, host="0.0.0.0", port=PORT)